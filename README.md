# Guru-Agent (Project Cortex) - Phase 1

## Active Cognitive Learning OS - Local RAG Foundation

**Team:** ZenForge
**Event:** AMD Slingshot Hackathon
**Version:** 0.1.0 - Phase 1
**Status:** Core Foundation Complete
**Privacy:** 100% Local Execution

---

## Overview

Guru-Agent is a local-first AI learning companion that provides personalized, empathetic educational support without relying on cloud services. Phase 1 establishes the core RAG (Retrieval-Augmented Generation) pipeline with generative UI capabilities.

### Phase 1 Features

âœ… **Document Processing**: Upload and process PDF, PowerPoint, and Word documents
âœ… **Local Vector Storage**: ChromaDB with sentence-transformers embeddings
âœ… **Local LLM Inference**: Ollama integration (Mistral-7B)
âœ… **Generative UI**: Automatic Mermaid.js diagram generation
âœ… **Next.js Frontend**: Modern, responsive chat interface
âœ… **Zero Cloud Dependency**: All processing happens locally

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js UI    â”‚
â”‚  (Port 3000)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backendâ”‚
â”‚  (Port 8000)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ChromaDBâ”‚ â”‚  Ollama  â”‚
â”‚ Vector â”‚ â”‚   LLM    â”‚
â”‚  Store â”‚ â”‚(Port     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ 11434)   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Start

### ğŸ³ Option 1: Docker (Recommended - Works Perfectly!)

**Requirements**: Docker Desktop installed ([Get Docker](https://docs.docker.com/get-docker/))

```bash
# Windows
scripts\docker-start.bat

# Linux/Mac
chmod +x scripts/docker-start.sh
./scripts/docker-start.sh
```

**That's it!** Full RAG system with ChromaDB, embeddings, and document processing. No dependency issues!

See [docs/DOCKER_SETUP.md](docs/DOCKER_SETUP.md) for details.

---

### ğŸ’» Option 2: Native Installation (Advanced)

### Prerequisites

1. **Python 3.10+**
2. **Node.js 18+**
3. **Ollama** (for local LLM)

### Installation

#### 1. Install Ollama & Pull Model

```bash
# Install Ollama (visit https://ollama.ai for your OS)
curl -fsSL https://ollama.ai/install.sh | sh

# Pull Mistral model
ollama pull mistral:7b

# Verify
ollama list
```

#### 2. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate (Windows: venv\Scripts\activate | Mac/Linux: source venv/bin/activate)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Copy environment file
cp .env.example .env
```

#### 3. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Copy environment file
cp .env.local.example .env.local
```

### Running the Application

**Terminal 1: Backend**
```bash
cd backend
source venv/bin/activate
python -m app.main
```
Backend: `http://localhost:8000` | Docs: `http://localhost:8000/docs`

**Terminal 2: Frontend**
```bash
cd frontend
npm run dev
```
Frontend: `http://localhost:3000`

---

## Usage

1. **Upload Documents**: Click "Upload Documents" and select PDF/PPTX/DOCX files
2. **Ask Questions**: Type your question about the uploaded materials
3. **View Responses**: Get AI-generated answers with source citations and auto-generated diagrams

---

## Project Structure

```
ZenForge/
â”œâ”€â”€ backend/                     # Python FastAPI
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py             # Entry point
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”‚   â”œâ”€â”€ models/             # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/           # Core logic (RAG, LLM, Vector DB)
â”‚   â”‚   â””â”€â”€ routers/            # API endpoints
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/                    # Next.js TypeScript
â”‚   â”œâ”€â”€ app/                    # App router
â”‚   â”œâ”€â”€ components/             # React components
â”‚   â”œâ”€â”€ lib/                    # API client
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ data/                       # Local storage (gitignored)
    â”œâ”€â”€ uploads/                # User documents
    â”œâ”€â”€ vectordb/               # ChromaDB
    â””â”€â”€ cache/                  # Temp files
```

---

## Configuration

### Backend (`.env`)

```bash
OLLAMA_MODEL=mistral:7b
EMBEDDING_MODEL=all-MiniLM-L6-v2
CHUNK_SIZE=1000
TOP_K_RETRIEVAL=4
```

### Frontend (`.env.local`)

```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

## Troubleshooting

**Ollama Offline**
```bash
ollama serve
ollama pull mistral:7b
```

**No Documents Indexed**
- Upload documents first via UI
- Check backend logs for errors

**Frontend Connection Error**
- Ensure backend is running on port 8000
- Verify `NEXT_PUBLIC_API_URL` in `.env.local`

---

## Roadmap

**Phase 2:** Multimodal & Multilingual (Vision tracking, Voice input, TTS)
**Phase 3:** Personalized Assessment (Hints, Rubrics, Role reversal)
**Phase 4:** Mastery Tracking (Spaced repetition, Gamification)

---

## License

Private project - AMD Slingshot Hackathon

---

**Built with â¤ï¸ for privacy-conscious learners**
